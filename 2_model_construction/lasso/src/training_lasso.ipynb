{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "final-graduate",
   "metadata": {},
   "source": [
    "# Lasso model\n",
    "9 combinations (sex x featureset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-substance",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re, glob, itertools\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a7a1f-a514-411e-95f3-21afe7cdff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859f18b-07ef-4e4d-9bc1-6fbf0cd1c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-wales",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b08a7f-edc5-493f-904f-f57b95f9d406",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3cc9e9-a7fe-43f8-990b-5b22f240fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(true_y, pred_y):\n",
    "    return np.mean(np.abs((true_y - pred_y) / true_y)) * 100\n",
    "\n",
    "loss = make_scorer(MAPE, greater_is_better=False)\n",
    "LOSS = \"MAPE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bed12-afe2-4425-b279-d58c8276c2ce",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6ee08e-7523-4b73-ac5c-8264a72d8b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, folds, scoring, DIR=\"\"):\n",
    "    alpha = trial.suggest_loguniform(\"alpha\", 1e-8, 1e2)\n",
    "    reg = Lasso(alpha=alpha, random_state=2021, max_iter=1000)\n",
    "    cv_results = cross_validate(reg, X, y, cv=folds, return_estimator=True, scoring=scoring, n_jobs=-1)\n",
    "    score = np.mean(cv_results[\"test_score\"]) * -1\n",
    "    if DIR:\n",
    "        joblib.dump(cv_results, os.path.join(DIR, f\"model_{trial.number}.pkl\"), compress=True)\n",
    "    return score\n",
    "\n",
    "def tune_lasso(X, y, folds, scoring, n_trials=50, DIR=\"\"):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(lambda trial: objective(trial, X, y, folds, scoring, DIR), n_trials=n_trials, callbacks=[logging_callback])\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9939f55-b2c5-443e-b164-b5ae88b257f0",
   "metadata": {},
   "source": [
    "## logging callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691b463-b87f-456f-8ece-e2d46b5a0371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logging_callback(study, frozen_trial):\n",
    "    previous_best_value = study.user_attrs.get(\"previous_best_value\", None)\n",
    "    if previous_best_value != study.best_value:\n",
    "        study.set_user_attr(\"previous_best_value\", study.best_value)\n",
    "        print(f\"Trial {frozen_trial.number} finished with best value: {frozen_trial.value} and parameters: {frozen_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592c58b-0611-4777-8663-1b2bf2c07d8c",
   "metadata": {},
   "source": [
    "## OOF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4a1a2-8802-40aa-bd09-03d0e1c7bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_oof(estimators, X, folds):\n",
    "    \"\"\"Calculate Out-of-Fold predictions from trained models.\"\"\"\n",
    "    oof_preds = np.zeros_like(X.iloc[:, 0], dtype=float)\n",
    "    for i, estimator in enumerate(estimators):\n",
    "        val_index = folds[i][1]\n",
    "        X_val = X.iloc[val_index]\n",
    "        oof_preds[val_index] = estimator.predict(X_val)\n",
    "    return oof_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51d1cd-0616-4a3c-be95-03a1297cf331",
   "metadata": {},
   "source": [
    "## Feature Importance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882b213-4ee8-46db-b5b3-8b6937d456ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_feature_coefficients(model, X, y, folds, scoring):\n",
    "    cv_results = cross_validate(model, X, y, cv=folds, return_estimator=True, scoring=scoring, n_jobs=-1)\n",
    "    importances = [est.coef_ for est in cv_results['estimator']]\n",
    "    mean_importances = np.abs(np.mean(importances, axis=0))\n",
    "    return mean_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06921dd9-a237-4250-b58e-56c09faf708a",
   "metadata": {},
   "source": [
    "## Null importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ba2b1-cec1-4b53-93ec-7cfe3968e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_null_importance(model, coefficient_func, X, y, folds, scoring, trials=20):\n",
    "    base_importance = coefficient_func(model, X, y, folds, scoring)\n",
    "    null_importances = []\n",
    "    for _ in tqdm(range(trials)):\n",
    "        y_permuted = np.random.permutation(y).flatten()\n",
    "        null_importance = coefficient_func(model, X, y_permuted, folds, scoring)\n",
    "        null_importances.append(null_importance)\n",
    "    null_importances = np.array(null_importances)\n",
    "    criterion_percentile = 50\n",
    "    percentile_null_imp = np.percentile(null_importances, criterion_percentile, axis=0)\n",
    "    null_imp_score = base_importance / (percentile_null_imp + 1e-6)\n",
    "    sorted_indices = np.argsort(null_imp_score)[::-1]\n",
    "    return null_imp_score, sorted_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38592004-d599-42de-9277-ed117658dc1b",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccc2fe-bcd3-4c68-88fb-76ea0430b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_percentage(model, X, y, folds, scoring, null_imp_score, sorted_indices, DIR, use_percentages):\n",
    "    sorted_columns = X.columns[sorted_indices]\n",
    "    mean_test_scores = []\n",
    "    \n",
    "    for percentage in tqdm(use_percentages):\n",
    "        num_of_features = int(len(sorted_columns) * percentage / 100)\n",
    "        if num_of_features == 0:\n",
    "            continue\n",
    "        selected_cols = sorted_columns[:num_of_features]\n",
    "        selected_X = X[selected_cols]\n",
    "        LOGGER.info(f'Null Importance score TOP {percentage}%')\n",
    "        LOGGER.info(f'Selected features: {list(selected_cols)}')\n",
    "        mean_test_score = cv_mean_test_score(model, selected_X, y, folds, scoring)\n",
    "        LOGGER.info(f'Mean test_score: {mean_test_score}')\n",
    "        mean_test_scores.append(mean_test_score)\n",
    "    \n",
    "    return mean_test_scores\n",
    "\n",
    "def select_features_by_num_features(model, X, y, folds, scoring, null_imp_score, sorted_indices, DIR, num_features_range):\n",
    "    sorted_columns = X.columns[sorted_indices]\n",
    "    selected_features_list = []\n",
    "    mean_test_scores = []\n",
    "    \n",
    "    for num_features in tqdm(num_features_range):\n",
    "        if num_features == 0:\n",
    "            continue\n",
    "        selected_cols = sorted_columns[:num_features]\n",
    "        selected_X = X[selected_cols]\n",
    "        LOGGER.info(f'Null Importance score TOP {num_features} features')\n",
    "        LOGGER.info(f'Selected features: {list(selected_cols)}')\n",
    "        mean_test_score = cv_mean_test_score(model, selected_X, y, folds, scoring)\n",
    "        LOGGER.info(f'Mean test_score: {mean_test_score}')\n",
    "        mean_test_scores.append(mean_test_score)\n",
    "        selected_features_list.append(selected_cols)\n",
    "    \n",
    "    selected_features = selected_features_list[np.argmin(mean_test_scores)]\n",
    "    joblib.dump(list(selected_features), os.path.join(DIR, \"selected_features_by_null_importance.pkl\"))\n",
    "    \n",
    "    return mean_test_scores, selected_features, selected_features_list\n",
    "\n",
    "def cv_mean_test_score(model, X, y, folds, scoring):\n",
    "    cv_results = cross_validate(model, X, y, cv=folds, return_estimator=True, scoring=scoring, n_jobs=-1)\n",
    "    oof_preds = predict_oof(cv_results['estimator'], X, folds)\n",
    "    return MAPE(y, oof_preds)\n",
    "\n",
    "def plot_feature_selection_results(mean_test_scores, DIR):\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "    ax1.plot(range(1, len(mean_test_scores) + 1), mean_test_scores, color='b', label='Mean test score')\n",
    "    ax1.set_xlabel('Importance TOP n features')\n",
    "    ax1.set_ylabel('Mean test score (MAPE)')\n",
    "    \n",
    "    min_index = np.argmin(mean_test_scores)\n",
    "    min_value = mean_test_scores[min_index]\n",
    "    \n",
    "    ax1.plot(min_index+1, min_value, 'ro')\n",
    "    ax1.text(min_index+1, min_value, f'features: {min_index+1}, Min: {min_value:.3f}', color='red')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(DIR, \"nullimportance_featureselection.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ca275-d8df-46d0-9a42-8beb5a80b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_and_save_best_model(X, y, folds, scoring, best_params, n_trials=200, DIR=\"\"):\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.enqueue_trial(best_params)\n",
    "    study.optimize(lambda trial: objective(trial, X, y, folds, scoring, DIR), n_trials=n_trials, callbacks=[logging_callback])\n",
    "    \n",
    "    for file in glob.glob(os.path.join(DIR, \"model_*.pkl\")):\n",
    "        i = int(re.findall(r\"\\d+\", file)[-1])\n",
    "        if i != study.best_trial.number:\n",
    "            os.remove(file)\n",
    "        else:\n",
    "            os.rename(file, os.path.join(DIR, \"bestmodel.pkl\"))\n",
    "    \n",
    "    best_model_cv = joblib.load(os.path.join(DIR, \"bestmodel.pkl\"))\n",
    "    return best_model_cv['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9489647-9e9c-4a30-aa6b-81bbc3add789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_results(test_y, y_pred_proba_avg, DIR):\n",
    "    \"\"\"Plot regression results.\"\"\"\n",
    "    finalMAPE = np.mean(np.abs(test_y.values - y_pred_proba_avg) / test_y.values) * 100\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.scatter(test_y.values, y_pred_proba_avg, label='test_samples',s=1)\n",
    "    \n",
    "    plt.xlabel(\"Chronological Age\")\n",
    "    plt.ylabel(\"Predicted Age\")\n",
    "    plt.grid(True)\n",
    "    plt.text(np.min(test_y), np.max(y_pred_proba_avg)-7, '$MAPE =$' + str(finalMAPE.round(3)))    \n",
    "    plt.savefig(os.path.join(DIR, \"pred_vs_true.pdf\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7910c-f2ad-4341-a246-bfc7902b984b",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipt_DIR = \"../../../0_data_processing/processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b857387-713d-4263-a944-3df03839ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = \"Lasso\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a20b66-ff42-410a-ae91-9442bac5c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_out = ['BOS','BOT', 'RR', 'FR', 'FAI', 'ATI']\n",
    "list_in = ['ONH_T','ONH_A', 'ONH_V', 'Choroid']\n",
    "prev_features = [x + \"_\" + y for x in list_in for y in list_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb4138-d0cf-4bd1-aeb5-391d03a19106",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = [\"0.99\"]\n",
    "SEX = [\"male\", \"female\", \"both\"]\n",
    "FTYPE = [\"prev\", \"tsfresh\", \"both\"]\n",
    "all_iter = itertools.product(R, SEX, FTYPE)\n",
    "\n",
    "use_feature_importance_top_percentages = [100, 75, 50, 40, 30, 25, 20, 15, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "kf = KFold(n_splits=5,random_state=2022,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bb7b1-83ee-4376-89e3-2176fdde7d2e",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation for All Sex-Feature Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40724ba-d1fd-4dbd-b53f-80f5f50480cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all combinations of parameters\n",
    "for r, sextype, featuretype in tqdm(all_iter, total=len(R)*len(SEX)*len(FTYPE)):\n",
    "    # Load data\n",
    "    y = pd.read_csv(os.path.join(ipt_DIR, \"y.csv\"), index_col=\"group.cmp\")\n",
    "    X = pd.read_csv(os.path.join(ipt_DIR, \"X_scaled.csv\"), index_col=\"group.cmp\")\n",
    "    folds_out = joblib.load(os.path.join(ipt_DIR, \"indices_5folds.pkl\"))\n",
    "    both_features = joblib.load(os.path.join(ipt_DIR, f\"tsfresh_features_var_0_r_{r}.pkl\"))\n",
    "    outDIR = os.path.join(\"../out\", LOSS, r, modeltype, sextype, featuretype)\n",
    "    os.makedirs(outDIR, exist_ok=True)\n",
    "    \n",
    "    # Select features based on feature type\n",
    "    if featuretype == \"prev\":\n",
    "        used_features = prev_features\n",
    "    elif featuretype == \"tsfresh\":\n",
    "        used_features = list(set(both_features) - set(prev_features))\n",
    "    elif featuretype == \"both\":\n",
    "        used_features = both_features\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for featuretype: {}\".format(featuretype))\n",
    "    \n",
    "    X = X[used_features]\n",
    "    y = y.reset_index()\n",
    "    X = X.reset_index()\n",
    "    \n",
    "    # Create a mapping from group.cmp to numeric indices\n",
    "    str_to_num_mapping = dict(zip(y[\"group.cmp\"], y.index))\n",
    "    # Update fold indices with numeric indices\n",
    "    for i in range(len(folds_out)):\n",
    "        folds_out[i] = (\n",
    "            [str_to_num_mapping[idx] for idx in folds_out[i][0]],\n",
    "            [str_to_num_mapping[idx] for idx in folds_out[i][1]]\n",
    "        )\n",
    "    \n",
    "    y = y.drop(columns=[\"group.cmp\"])\n",
    "    X = X.drop(columns=[\"group.cmp\"])\n",
    "\n",
    "    # Filter data by sex type    \n",
    "    if sextype != \"both\":\n",
    "        if sextype == \"male\":\n",
    "            ind = np.array(y[y[\"SEX.男1.女0\"] == 1].index)\n",
    "        elif sextype == \"female\":\n",
    "            ind = np.array(y[y[\"SEX.男1.女0\"] == 0].index)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for sextype: {}\".format(sextype))\n",
    "        \n",
    "        y = y.loc[ind]\n",
    "        X = X.loc[ind].reset_index()\n",
    "        index_mapping = dict(zip(list(X[\"index\"]), list(X.index)))\n",
    "        X = X.drop([\"index\"], axis=1)\n",
    "        y = y.loc[ind].reset_index().drop([\"index\"], axis=1)\n",
    "        # Update fold indices with new mapping\n",
    "        new_folds_out = []\n",
    "        for train_idx, test_idx in folds_out:\n",
    "            new_train_idx = [index_mapping[idx] for idx in train_idx if idx in index_mapping]\n",
    "            new_test_idx = [index_mapping[idx] for idx in test_idx if idx in index_mapping]\n",
    "            new_folds_out.append((new_train_idx, new_test_idx))\n",
    "        folds_out = new_folds_out\n",
    "                \n",
    "    os.makedirs(os.path.join(outDIR, \"optuna\"), exist_ok=True)\n",
    "    \n",
    "    # Define initial parameters using tune_lasso function\n",
    "    best_params = tune_lasso(X, y[\"Age\"], folds_out, loss, n_trials=50, DIR=\"\")\n",
    "    best_alpha = best_params[\"alpha\"]\n",
    "    \n",
    "    lasso_reg = Lasso(alpha=best_alpha, random_state=2022, max_iter=1000)\n",
    "    null_imp_score, sorted_indices = analyse_null_importance(lasso_reg, calculate_feature_coefficients, X, y[\"Age\"], folds_out, loss)\n",
    "\n",
    "    # First feature selection to reduce calculation\n",
    "    num_selected_features = sum(null_imp_score > 1)\n",
    "    # Select columns based on sorted indices and number of selected features\n",
    "    sorted_columns = X.columns[sorted_indices]\n",
    "    X = X[sorted_columns].iloc[:, :num_selected_features]\n",
    "    sorted_indices = np.arange(X.shape[1])\n",
    "    \n",
    "    if featuretype == \"prev\":\n",
    "        mean_test_scores, selected_features, selected_features_list = select_features_by_num_features(\n",
    "            lasso_reg, X, y[\"Age\"], folds_out, loss, null_imp_score, sorted_indices, outDIR, num_features_range=range(1, len(sorted_indices) + 1))\n",
    "    else:\n",
    "        # Rough survey using use_feature_importance_top_percentages\n",
    "        mean_test_scores = select_features_by_percentage(\n",
    "            lasso_reg, X, y[\"Age\"], folds_out, loss, null_imp_score, sorted_indices, outDIR, use_percentages=use_feature_importance_top_percentages)\n",
    "        \n",
    "        # Detailed surveys\n",
    "        best_index = np.argmin(mean_test_scores)\n",
    "        detailed_percentages_upto = use_feature_importance_top_percentages[max(0, best_index-1)]\n",
    "        num_features_for_detailed = int(np.ceil(len(sorted_indices) * detailed_percentages_upto / 100))\n",
    "        \n",
    "        mean_test_scores, selected_features, selected_features_list = select_features_by_num_features(\n",
    "            lasso_reg, X, y[\"Age\"], folds_out, loss, null_imp_score, sorted_indices, outDIR, num_features_range=range(1, num_features_for_detailed + 1))\n",
    "        \n",
    "    plot_feature_selection_results(mean_test_scores, outDIR)\n",
    "\n",
    "    # nested CV\n",
    "    pred_y=np.zeros(y.shape[0])\n",
    "    for i, f in enumerate(folds_out):\n",
    "        y_pred_proba_list = []\n",
    "        tr_ind, te_ind = f[0], f[1]\n",
    "        tr_x = X.iloc[tr_ind, :].loc[:, selected_features]\n",
    "        te_x = X.iloc[te_ind, :].loc[:, selected_features]\n",
    "        tr_y = y.iloc[tr_ind, :][\"Age\"]\n",
    "        te_y = y.iloc[te_ind, :][\"Age\"]\n",
    "        folds_in = list(kf.split(tr_x, tr_y))\n",
    "        DIRinloop = os.path.join(outDIR, \"optuna\", f\"outer_{i}\")\n",
    "        os.makedirs(DIRinloop, exist_ok=True)\n",
    "        best_lasso_models_tmp = optimize_and_save_best_model(tr_x, tr_y, folds_in, loss, best_params, n_trials=200, DIR=DIRinloop)\n",
    "        for best_model in best_lasso_models_tmp:\n",
    "            tmp_y_pred = best_model.predict(te_x)\n",
    "            y_pred_proba_list.append(tmp_y_pred)\n",
    "        y_pred_proba_avg = np.array(y_pred_proba_list).mean(axis=0)\n",
    "        pred_y[te_ind] = y_pred_proba_avg        \n",
    "    \n",
    "    if sextype == \"male\":\n",
    "        pred_y = pred_y[np.array(y[y[\"SEX.男1.女0\"] == 1].index)]\n",
    "        true_y = y[y[\"SEX.男1.女0\"] == 1].copy()\n",
    "    elif sextype == \"female\":\n",
    "        pred_y = pred_y[np.array(y[y[\"SEX.男1.女0\"] == 0].index)]\n",
    "        true_y = y[y[\"SEX.男1.女0\"] == 0].copy()\n",
    "    elif sextype == \"both\":\n",
    "        true_y = y.copy()\n",
    "    \n",
    "    plot_regression_results(true_y[\"Age\"], pred_y, outDIR)\n",
    "    true_y[\"Predicted_age\"] = pred_y\n",
    "    true_y.to_csv(os.path.join(outDIR, \"pred_vs_true.csv\"))\n",
    "\n",
    "    # plot coefficitnes\n",
    "    coefs = []\n",
    "    for bestDIR in glob.glob(os.path.join(outDIR, \"optuna\", \"**\", \"bestmodel.pkl\"), recursive=True):\n",
    "        best_lasso_cv = joblib.load(bestDIR)\n",
    "        best_lasso_models = best_lasso_cv['estimator']\n",
    "        coefs_tmp = [best_model.coef_ for best_model in best_lasso_models]\n",
    "        coefs.extend(coefs_tmp)\n",
    "    \n",
    "    mean_coefs = np.mean(coefs, axis=0)\n",
    "    feature_names = X[selected_features].columns\n",
    "    importance_df = pd.DataFrame(data=coefs, columns=feature_names)\n",
    "    \n",
    "    sorted_indices_coef = importance_df.mean(axis=0).abs().sort_values(ascending=False).index\n",
    "    sorted_importance_df = importance_df.loc[:, sorted_indices_coef]\n",
    "    \n",
    "    tops = [10, 20, 50, 200]\n",
    "    for i in tops:\n",
    "        PLOT_TOP_N = i\n",
    "        plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]\n",
    "        _, ax = plt.subplots(figsize=(8, i*0.3))\n",
    "        ax.grid()\n",
    "        ax.set_ylabel('Feature')\n",
    "        ax.set_xlabel('Coefficients')\n",
    "        ax.axvline(0, ls='-', color=\"black\", lw=1)\n",
    "        sns.boxplot(data=sorted_importance_df[plot_cols], boxprops=dict(alpha=.3), orient='h', ax=ax)\n",
    "        plt.savefig(os.path.join(outDIR, f'feature_coefs_top{PLOT_TOP_N}.pdf'), bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    \n",
    "    sorted_importance_df.to_csv(os.path.join(outDIR, 'feature_coefs.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
