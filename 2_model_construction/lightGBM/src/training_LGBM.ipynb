{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "final-graduate",
   "metadata": {},
   "source": [
    "# LightGBM model\n",
    "9 combinations (sex x featureset)  \n",
    "Hyper param tuning by LightGBMTunerCV  \n",
    "\n",
    "lightgbm==3.3.5  \n",
    "optuna==2.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-substance",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, re, glob, itertools\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a7a1f-a514-411e-95f3-21afe7cdff0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['font.family'] = 'Arial'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859f18b-07ef-4e4d-9bc1-6fbf0cd1c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGGER = logging.getLogger(__name__)\n",
    "\n",
    "from optuna.integration import lightgbm as lgb\n",
    "from optuna.integration.lightgbm import LightGBMTunerCV\n",
    "optuna.logging.set_verbosity(optuna.logging.WARN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03a438e-7526-4fa2-ae86-5ea2734f8644",
   "metadata": {},
   "source": [
    "# Define callback class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afda81-514b-4f9f-a711-41158fd95325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelExtractionCallback(object):\n",
    "    \"\"\"Class for extracting trained models from lightgbm.cv() using callbacks.\n",
    "\n",
    "    NOTE: This class relies on the non-public class '_CVBooster', \n",
    "    which may not work in future versions of LightGBM.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._model = None\n",
    "\n",
    "    def __call__(self, env):\n",
    "        # Keep a reference to the _CVBooster\n",
    "        self._model = env.model\n",
    "\n",
    "    def _assert_called_cb(self):\n",
    "        if self._model is None:\n",
    "            # Raise an exception if the callback has not been called\n",
    "            raise RuntimeError('callback has not been called yet')\n",
    "\n",
    "    @property\n",
    "    def boosters_proxy(self):\n",
    "        self._assert_called_cb()\n",
    "        # Return a proxy object to the Booster\n",
    "        return self._model\n",
    "\n",
    "    @property\n",
    "    def raw_boosters(self):\n",
    "        self._assert_called_cb()\n",
    "        # Return a list of Boosters\n",
    "        return self._model.boosters\n",
    "\n",
    "    @property\n",
    "    def best_iteration(self):\n",
    "        self._assert_called_cb()\n",
    "        # Return the boosting round at early stopping\n",
    "        return self._model.best_iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-wales",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b08a7f-edc5-493f-904f-f57b95f9d406",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3cc9e9-a7fe-43f8-990b-5b22f240fd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(true_y, pred_y):\n",
    "    return np.mean(np.abs((true_y - pred_y) / true_y)) * 100\n",
    "\n",
    "loss = make_scorer(MAPE, greater_is_better=False)\n",
    "LOSS = \"MAPE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bed12-afe2-4425-b279-d58c8276c2ce",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d26357f-d17e-4485-b07e-2ba5f5db9586",
   "metadata": {},
   "source": [
    "### Cross_validate (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0d427-e306-4e51-acc6-87faa5745d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _cross_validate(X, y, folds, params):\n",
    "    \"\"\"Function to perform cross-validation using LightGBM\"\"\"\n",
    "    lgb_train = lgb.Dataset(X, y)\n",
    "    callbacks = [\n",
    "        lgb.log_evaluation(10000),\n",
    "        lgb.early_stopping(100),\n",
    "    ]\n",
    "    lgbcv = lgb.cv(params,\n",
    "                   lgb_train,\n",
    "                   folds=folds,\n",
    "                   num_boost_round=1000,\n",
    "                   return_cvbooster=True,\n",
    "                   callbacks=callbacks)\n",
    "    return lgbcv[\"cvbooster\"]\n",
    "\n",
    "def cv_mean_test_score(X, y, folds, params):\n",
    "    \"\"\"Function to calculate the mean test score for Out-of-Fold predictions\"\"\"\n",
    "    cv_booster = _cross_validate(X, y, folds, params)\n",
    "    oof_y_pred = _predict_oof(cv_booster, X, y, folds)\n",
    "    test_score = MAPE(y, oof_y_pred)\n",
    "    \n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0592c58b-0611-4777-8663-1b2bf2c07d8c",
   "metadata": {},
   "source": [
    "## OOF predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4a1a2-8802-40aa-bd09-03d0e1c7bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _predict_oof(cv_booster, X, y, folds):\n",
    "    \"\"\"Function to obtain Out-of-Fold predictions from trained models\"\"\"\n",
    "    oof_y_preds = np.zeros_like(y.squeeze(), dtype=float)\n",
    "    for i in range(len(cv_booster.boosters)):\n",
    "        booster = cv_booster.boosters[i]\n",
    "        val_index = folds[i][1]\n",
    "        val_train_x = X.iloc[val_index]\n",
    "        oof_y_preds[val_index] = booster.predict(val_train_x, num_iteration=cv_booster.best_iteration)\n",
    "    return oof_y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51d1cd-0616-4a3c-be95-03a1297cf331",
   "metadata": {},
   "source": [
    "## Feature Importance Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e882b213-4ee8-46db-b5b3-8b6937d456ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_mean_feature_importance(X, y, folds, params):\n",
    "    \"\"\"Function to calculate feature importance using cross-validated models\"\"\"\n",
    "    cv_booster = _cross_validate(X, y, folds, params)\n",
    "    importances = [booster.feature_importance(importance_type='gain') for booster in cv_booster.boosters]\n",
    "    mean_importance = np.mean(importances, axis=0)\n",
    "    return mean_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06921dd9-a237-4250-b58e-56c09faf708a",
   "metadata": {},
   "source": [
    "## Null importance analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ba2b1-cec1-4b53-93ec-7cfe3968e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_null_importance(X, y, folds, params, percentile=50, trials=20):\n",
    "    \"\"\"\n",
    "    inputs: X, y, folds ->\n",
    "    * calc feature importance [base_importance]\n",
    "    * calc feature importance with randomized y [null_importance] for TRIALS_N times\n",
    "    * compare criterion_percentile percentile of null_importance\n",
    "    \n",
    "    return base_importance:null_importance ratio [null_imp_score]\n",
    "        and\n",
    "        sorted_indices which indicates the sorted feature index by null_imp_score\n",
    "    \"\"\"\n",
    "    LOGGER.info('Starting base importance calculation')\n",
    "    base_importance = cv_mean_feature_importance(X, y, folds, params)\n",
    "    \n",
    "    LOGGER.info('Starting null importance calculation')\n",
    "    null_importances = []\n",
    "    for _ in tqdm(range(trials)):\n",
    "        train_y_permuted = np.random.permutation(y).flatten()\n",
    "        null_importance = cv_mean_feature_importance(X, train_y_permuted, folds, params)\n",
    "        null_importances.append(null_importance)\n",
    "    null_importances = np.array(null_importances)\n",
    "\n",
    "    percentile_null_imp = np.percentile(null_importances, percentile, axis=0)\n",
    "    null_imp_score = base_importance / (percentile_null_imp + 1e-6)\n",
    "    sorted_indices = np.argsort(null_imp_score)[::-1]\n",
    "    \n",
    "    return null_imp_score, sorted_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38592004-d599-42de-9277-ed117658dc1b",
   "metadata": {},
   "source": [
    "## Feature selection by null importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fccc2fe-bcd3-4c68-88fb-76ea0430b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_percentage(X, y, folds, params, scoring, null_imp_score, sorted_indices, DIR, use_percentages):\n",
    "    sorted_columns = X.columns[sorted_indices]\n",
    "    mean_test_scores = []\n",
    "    \n",
    "    for percentage in tqdm(use_percentages):\n",
    "        num_of_features = int(len(sorted_columns) * percentage / 100)\n",
    "        if num_of_features == 0:\n",
    "            continue\n",
    "        selected_cols = sorted_columns[:num_of_features]\n",
    "        selected_X = X[selected_cols]\n",
    "        LOGGER.info(f'Null Importance score TOP {percentage}%')\n",
    "        LOGGER.info(f'Selected features: {list(selected_cols)}')\n",
    "        mean_test_score = cv_mean_test_score(selected_X, y, folds, params, )#scoring)\n",
    "        LOGGER.info(f'Mean test_score: {mean_test_score}')\n",
    "        mean_test_scores.append(mean_test_score)\n",
    "    \n",
    "    return mean_test_scores\n",
    "\n",
    "def select_features_by_num_features(X, y, folds, params, scoring, null_imp_score, sorted_indices, DIR, num_features_range):\n",
    "    sorted_columns = X.columns[sorted_indices]\n",
    "    selected_features_list = []\n",
    "    mean_test_scores = []\n",
    "    \n",
    "    for num_features in tqdm(num_features_range):\n",
    "        if num_features == 0:\n",
    "            continue\n",
    "        selected_cols = sorted_columns[:num_features]\n",
    "        selected_X = X[selected_cols]\n",
    "        LOGGER.info(f'Null Importance score TOP {num_features} features')\n",
    "        LOGGER.info(f'Selected features: {list(selected_cols)}')\n",
    "        mean_test_score = cv_mean_test_score(selected_X, y, folds, params, )#scoring)\n",
    "        LOGGER.info(f'Mean test_score: {mean_test_score}')\n",
    "        mean_test_scores.append(mean_test_score)\n",
    "        selected_features_list.append(selected_cols)\n",
    "    \n",
    "    selected_features = selected_features_list[np.argmin(mean_test_scores)]\n",
    "    joblib.dump(list(selected_features), os.path.join(DIR, \"selected_features_by_null_importance.pkl\"))\n",
    "    \n",
    "    return mean_test_scores, selected_features, selected_features_list\n",
    "\n",
    "\n",
    "def plot_feature_selection_results(mean_test_scores, DIR):\n",
    "    \n",
    "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
    "    ax1.plot(range(1, len(mean_test_scores) + 1), mean_test_scores, color='b', label='Mean test score')\n",
    "    ax1.set_xlabel('Importance TOP n features')\n",
    "    ax1.set_ylabel('Mean test score (RMSE)')\n",
    "    \n",
    "    min_index = np.argmin(mean_test_scores)\n",
    "    min_value = mean_test_scores[min_index]\n",
    "    \n",
    "    ax1.plot(min_index+1, min_value, 'ro')\n",
    "    ax1.text(min_index+1, min_value, f'features: {min_index+1}, Min: {min_value:.3f}', color='red')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(os.path.join(DIR, \"nullimportance_featureselection.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec224f2c-4bc6-4870-b850-b5d741382fd6",
   "metadata": {},
   "source": [
    "## parameter tuning by inner CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f8cc1c-d9aa-47ed-8919-c6b44ae5f7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_optim_loop(X, y, folds, best_params_before_featureselection, DIRinloop):\n",
    "    \"\"\"\n",
    "    Function to perform parameter optimization and model training using LightGBM.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): Training features.\n",
    "        y (pd.Series): Training labels.\n",
    "        folds (list): List of fold indices for cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        boosters (list): List of trained LightGBM booster models.\n",
    "        best_iteration (int): The best iteration number.\n",
    "    \"\"\"\n",
    "    train_set = lgb.Dataset(X, label=y)\n",
    "\n",
    "    best_params = {}\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(100),\n",
    "        lgb.log_evaluation(10_000),\n",
    "              ]\n",
    "    # Initialize LightGBM tuner for cross-validation    \n",
    "    tunercv = LightGBMTunerCV(best_params_before_featureselection,\n",
    "                        train_set,\n",
    "                        num_boost_round=2000,\n",
    "                        verbose_eval=False,\n",
    "                        folds=folds,\n",
    "                        callbacks=callbacks)    \n",
    "    \n",
    "    # Run the tuner\n",
    "    tunercv.run()\n",
    "    best_params = tunercv.best_params\n",
    "    \n",
    "    # Save the best parameters to a file\n",
    "    joblib.dump(best_params, os.path.join(DIRinloop, \"best_params.pkl\"))\n",
    "\n",
    "    # Prepare callback for extracting trained models\n",
    "    extraction_cb = ModelExtractionCallback()\n",
    "    callbacks = [\n",
    "        extraction_cb,\n",
    "        lgb.log_evaluation(10_000),\n",
    "    ]\n",
    "\n",
    "    # Train the model with the best parameters\n",
    "    cv_result = lgb.cv(params=best_params,num_boost_round=100_000,\n",
    "                   train_set=train_set,\n",
    "                   early_stopping_rounds=50,\n",
    "                   folds=folds,\n",
    "                   callbacks=callbacks,\n",
    "                   return_cvbooster=True,)\n",
    "   # Extract trained models from the callback\n",
    "    proxy = extraction_cb.boosters_proxy\n",
    "    boosters = extraction_cb.raw_boosters\n",
    "    best_iteration = extraction_cb.best_iteration\n",
    "    \n",
    "    # Save the best iteration number and models\n",
    "    joblib.dump(best_iteration,  os.path.join(DIRinloop, \"/best_iterNO.pkl\"))\n",
    "    for p, booster in enumerate(boosters):\n",
    "        booster.save_model(os.path.join(DIRinloop, f\"model_{p}.txt\"))\n",
    "\n",
    "    return boosters, best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9489647-9e9c-4a30-aa6b-81bbc3add789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_results(test_y, y_pred_proba_avg, DIR):\n",
    "    \"\"\"Plot regression results.\"\"\"\n",
    "    finalMAPE = np.mean(np.abs(test_y.values - y_pred_proba_avg) / test_y.values) * 100\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.scatter(test_y.values, y_pred_proba_avg, label='test_samples',s=1)\n",
    "    \n",
    "    plt.xlabel(\"Chronological Age\")\n",
    "    plt.ylabel(\"Predicted Age\")\n",
    "    plt.grid(True)\n",
    "    plt.text(np.min(test_y), np.max(y_pred_proba_avg)-7, '$MAPE =$' + str(finalMAPE.round(3)))    \n",
    "    plt.savefig(os.path.join(DIR, \"pred_vs_true.pdf\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d7910c-f2ad-4341-a246-bfc7902b984b",
   "metadata": {},
   "source": [
    "# Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipt_DIR = \"../../../0_data_processing/processed_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b857387-713d-4263-a944-3df03839ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltype = \"LGBM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a20b66-ff42-410a-ae91-9442bac5c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_out = ['BOS','BOT', 'RR', 'FR', 'FAI', 'ATI']\n",
    "list_in = ['ONH_T','ONH_A', 'ONH_V', 'Choroid']\n",
    "prev_features = [x + \"_\" + y for x in list_in for y in list_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb4138-d0cf-4bd1-aeb5-391d03a19106",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = [\"0.99\"]\n",
    "SEX = [\"male\", \"female\", \"both\"]\n",
    "FTYPE = [\"prev\", \"tsfresh\", \"both\"]\n",
    "all_iter = itertools.product(R, SEX, FTYPE)\n",
    "\n",
    "use_feature_importance_top_percentages = [100, 75, 50, 40, 30, 25, 20, 15, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
    "kf = KFold(n_splits=5,random_state=2022,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dba9be-db81-4c38-9233-0f1f915a963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': \"mape\",\n",
    "    'verbosity': -1,\n",
    "    \"max_depth\": -1,\n",
    "    'feature_pre_filter': False,\n",
    "    'lambda_l1': 1e-06,\n",
    "    'lambda_l2': 1e-07,\n",
    "    'num_leaves': 255,\n",
    "    'feature_fraction': 0.6,\n",
    "    \"seed\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237bb7b1-83ee-4376-89e3-2176fdde7d2e",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation for All Sex-Feature Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40724ba-d1fd-4dbd-b53f-80f5f50480cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate over all combinations of parameters\n",
    "for r, sextype, featuretype in tqdm(all_iter, total=len(R)*len(SEX)*len(FTYPE)):\n",
    "    # Load data\n",
    "    y = pd.read_csv(os.path.join(ipt_DIR, \"y.csv\"), index_col=\"group.cmp\")\n",
    "    X = pd.read_csv(os.path.join(ipt_DIR, \"X_scaled.csv\"), index_col=\"group.cmp\")\n",
    "    folds_out = joblib.load(os.path.join(ipt_DIR, \"indices_5folds.pkl\"))\n",
    "    both_features = joblib.load(os.path.join(ipt_DIR, f\"tsfresh_features_var_0_r_{r}.pkl\"))\n",
    "    outDIR = os.path.join(\"../out\", LOSS, r, modeltype, sextype, featuretype)\n",
    "    os.makedirs(outDIR, exist_ok=True)\n",
    "    \n",
    "    # Select features based on feature type\n",
    "    if featuretype == \"prev\":\n",
    "        used_features = prev_features\n",
    "    elif featuretype == \"tsfresh\":\n",
    "        used_features = list(set(both_features) - set(prev_features))\n",
    "    elif featuretype == \"both\":\n",
    "        used_features = both_features\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for featuretype: {}\".format(featuretype))\n",
    "    \n",
    "    X = X[used_features]\n",
    "    y = y.reset_index()\n",
    "    X = X.reset_index()\n",
    "    \n",
    "    # Create a mapping from group.cmp to numeric indices\n",
    "    str_to_num_mapping = dict(zip(y[\"group.cmp\"], y.index))\n",
    "    # Update fold indices with numeric indices\n",
    "    for i in range(len(folds_out)):\n",
    "        folds_out[i] = (\n",
    "            [str_to_num_mapping[idx] for idx in folds_out[i][0]],\n",
    "            [str_to_num_mapping[idx] for idx in folds_out[i][1]]\n",
    "        )\n",
    "    \n",
    "    y = y.drop(columns=[\"group.cmp\"])\n",
    "    X = X.drop(columns=[\"group.cmp\"])\n",
    "    \n",
    "    # Filter data by sex type    \n",
    "    if sextype != \"both\":\n",
    "        if sextype == \"male\":\n",
    "            ind = np.array(y[y[\"SEX.男1.女0\"] == 1].index)\n",
    "        elif sextype == \"female\":\n",
    "            ind = np.array(y[y[\"SEX.男1.女0\"] == 0].index)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for sextype: {}\".format(sextype))\n",
    "        \n",
    "        y = y.loc[ind]\n",
    "        X = X.loc[ind].reset_index()\n",
    "        index_mapping = dict(zip(list(X[\"index\"]), list(X.index)))\n",
    "        X = X.drop([\"index\"], axis=1)\n",
    "        y = y.loc[ind].reset_index().drop([\"index\"], axis=1)\n",
    "        # Update fold indices with new mapping\n",
    "        new_folds_out = []\n",
    "        for train_idx, test_idx in folds_out:\n",
    "            new_train_idx = [index_mapping[idx] for idx in train_idx if idx in index_mapping]\n",
    "            new_test_idx = [index_mapping[idx] for idx in test_idx if idx in index_mapping]\n",
    "            new_folds_out.append((new_train_idx, new_test_idx))\n",
    "        folds_out = new_folds_out\n",
    "                \n",
    "    os.makedirs(os.path.join(outDIR, \"optuna\"), exist_ok=True)\n",
    "    \n",
    "    # Analyse null importance with initial parameters\n",
    "    null_imp_score, sorted_indices = analyse_null_importance(X, y[\"Age\"], folds_out, initial_params)\n",
    "    # First feature selection to reduce calculation\n",
    "    num_selected_features = sum(null_imp_score > 1)\n",
    "    # Select columns based on sorted indices and number of selected features\n",
    "    sorted_columns = X.columns[sorted_indices]\n",
    "    X = X[sorted_columns].iloc[:, :num_selected_features]\n",
    "    sorted_indices = np.arange(X.shape[1])\n",
    "    \n",
    "    # Hyper parameter optimization for feature selection from remained features\n",
    "    train_set = lgb.Dataset(X, label=y[\"Age\"])\n",
    "    callbacks=[lgb.early_stopping(100),lgb.log_evaluation(10000),]\n",
    "    tunercv_first = LightGBMTunerCV(initial_params,\n",
    "                        train_set,\n",
    "                        num_boost_round=2000,\n",
    "                        verbose_eval=False,\n",
    "                        folds=folds_out,\n",
    "                        callbacks=callbacks)    \n",
    "    tunercv_first.run()\n",
    "    \n",
    "    # Save the best parameters before feature selection to a file\n",
    "    best_params_before_featureselection = tunercv_first.best_params\n",
    "    best_params_before_filepath = os.path.join(outDIR, \"best_params_before_featureselection.pkl\")\n",
    "    joblib.dump(best_params_before_featureselection, best_params_before_filepath)\n",
    "\n",
    "    # calc. null importance    \n",
    "    if featuretype == \"prev\":\n",
    "        mean_test_scores, selected_features, selected_features_list = select_features_by_num_features(\n",
    "            X, y[\"Age\"], folds_out, best_params_before_featureselection, loss, null_imp_score, sorted_indices, outDIR, num_features_range=range(1, len(sorted_indices) + 1))\n",
    "    else:\n",
    "        # Rough survey using use_feature_importance_top_percentages\n",
    "        mean_test_scores = select_features_by_percentage(\n",
    "            X, y[\"Age\"], folds_out, best_params_before_featureselection, loss, null_imp_score, sorted_indices, outDIR, use_percentages=use_feature_importance_top_percentages)\n",
    "    \n",
    "        # Detailed surveys\n",
    "        best_index = np.argmin(mean_test_scores)\n",
    "        detailed_percentages_upto = use_feature_importance_top_percentages[max(0, best_index-1)]\n",
    "        num_features_for_detailed = int(np.ceil(len(sorted_indices) * detailed_percentages_upto / 100))\n",
    "            \n",
    "        mean_test_scores, selected_features, selected_features_list = select_features_by_num_features(\n",
    "            X, y[\"Age\"], folds_out, best_params_before_featureselection, loss, null_imp_score, sorted_indices, outDIR, num_features_range=range(1, num_features_for_detailed + 1))\n",
    "    \n",
    "    plot_feature_selection_results(mean_test_scores, outDIR)\n",
    "\n",
    "    # nested CV\n",
    "    pred_y=np.zeros(y.shape[0])\n",
    "    for i, f in enumerate(folds_out):\n",
    "        y_pred_proba_list = []\n",
    "        tr_ind, te_ind = f[0], f[1]\n",
    "        tr_x = X.iloc[tr_ind, :].loc[:, selected_features]\n",
    "        te_x = X.iloc[te_ind, :].loc[:, selected_features]\n",
    "        tr_y = y.iloc[tr_ind, :][\"Age\"]\n",
    "        te_y = y.iloc[te_ind, :][\"Age\"]\n",
    "        folds_in = list(kf.split(tr_x, tr_y))\n",
    "        DIRinloop = os.path.join(outDIR, \"optuna\", f\"outer_{i}\")\n",
    "        os.makedirs(DIRinloop, exist_ok=True)\n",
    "        \n",
    "        proxy, best_iteration = param_optim_loop(tr_x,tr_y,folds_in, best_params_before_featureselection, DIRinloop)\n",
    "    \n",
    "        for best_model in proxy:\n",
    "            tmp_y_pred = best_model.predict(te_x, num_iteration=best_iteration)\n",
    "            y_pred_proba_list.append(tmp_y_pred)\n",
    "        y_pred_proba_avg = np.array(y_pred_proba_list).mean(axis=0)\n",
    "        pred_y[te_ind] = y_pred_proba_avg\n",
    "               \n",
    "    if sextype == \"male\":\n",
    "        pred_y = pred_y[np.array(y[y[\"SEX.男1.女0\"] == 1].index)]\n",
    "        true_y = y[y[\"SEX.男1.女0\"] == 1].copy()\n",
    "    elif sextype == \"female\":\n",
    "        pred_y = pred_y[np.array(y[y[\"SEX.男1.女0\"] == 0].index)]\n",
    "        true_y = y[y[\"SEX.男1.女0\"] == 0].copy()\n",
    "    elif sextype == \"both\":\n",
    "        true_y = y.copy()\n",
    "    \n",
    "    plot_regression_results(true_y[\"Age\"], pred_y, outDIR)\n",
    "    true_y[\"Predicted_age\"] = pred_y\n",
    "    true_y.to_csv(os.path.join(outDIR, \"pred_vs_true.csv\"))\n",
    "\n",
    "    # plot coefficients\n",
    "    cvbooster_from_file=lgb.CVBooster()\n",
    "    for bestDIR in glob.glob(outDIR+\"/optuna/**/*/model_*.txt\", recursive=True):\n",
    "        tmp_booster = lgb.Booster(model_file = bestDIR)\n",
    "        cvbooster_from_file.boosters.append(tmp_booster)\n",
    "    raw_importances = cvbooster_from_file.feature_importance(importance_type='gain')\n",
    "    feature_name = cvbooster_from_file.boosters[0].feature_name()\n",
    "    importance_df = pd.DataFrame(data=raw_importances,\n",
    "                                 columns=feature_name)\n",
    "    \n",
    "    sorted_indices = importance_df.mean(axis=0).sort_values(ascending=False).index\n",
    "    sorted_importance_df = importance_df.loc[:, sorted_indices]\n",
    "\n",
    "    tops = [10, 20, 50, 200]\n",
    "    for i in tops:\n",
    "        PLOT_TOP_N = i\n",
    "        plot_cols = sorted_importance_df.columns[:PLOT_TOP_N]\n",
    "        _, ax = plt.subplots(figsize=(8, i*0.3))\n",
    "        ax.grid()\n",
    "        ax.set_xscale('symlog')\n",
    "        ax.set_ylabel('Feature')\n",
    "        ax.set_xlabel('Importance')\n",
    "        sns.boxplot(data=sorted_importance_df[plot_cols], boxprops=dict(alpha=.3),\n",
    "                    orient='h',\n",
    "                    ax=ax)\n",
    "        # Save the plot as a PDF file\n",
    "        plot_filename = os.path.join(outDIR, f'feature_importance_top{PLOT_TOP_N}.pdf')\n",
    "        plt.savefig(plot_filename, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    # Save the sorted importance dataframe to a CSV file\n",
    "    importance_csv_filepath = os.path.join(outDIR, 'feature_importance.csv')\n",
    "    sorted_importance_df.to_csv(importance_csv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab194b95-de48-4473-b688-af8973d9dde7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
